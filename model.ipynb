{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Flatten, Lambda, Activation, MaxPooling2D,SpatialDropout2D,Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import DataProvider\n",
    "\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "number_of_epochs = 10\n",
    "number_of_samples_per_epoch = 20032\n",
    "number_of_validation_samples = 6400\n",
    "learning_rate = 1e-4\n",
    "activation_relu = 'relu'\n",
    "\n",
    "# Our model is based on NVIDIA's \"End to End Learning for Self-Driving Cars\" paper\n",
    "# Source:  https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "class BehavioralCloningModel():\n",
    "    def __init__(self):\n",
    "        self.model = self.__nvidia_like()\n",
    "        self.history = None\n",
    "        \n",
    "    def __nvidia_like(self):\n",
    "        model = Sequential()\n",
    "        model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape=(64, 64, 3)))\n",
    "        # starts with five convolutional and maxpooling layers\n",
    "        model.add(Convolution2D(24, 5, 5, border_mode='same', subsample=(2, 2)))\n",
    "        model.add(Activation(activation_relu))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "        model.add(SpatialDropout2D(0.2))\n",
    "\n",
    "        model.add(Convolution2D(36, 5, 5, border_mode='same', subsample=(2, 2)))\n",
    "        model.add(Activation(activation_relu))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "        model.add(SpatialDropout2D(0.2))\n",
    "\n",
    "        model.add(Convolution2D(48, 5, 5, border_mode='same', subsample=(2, 2)))\n",
    "        model.add(Activation(activation_relu))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "        model.add(SpatialDropout2D(0.2))\n",
    "\n",
    "        model.add(Convolution2D(64, 3, 3, border_mode='same', subsample=(1, 1)))\n",
    "        model.add(Activation(activation_relu))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "        model.add(SpatialDropout2D(0.2))\n",
    "\n",
    "        model.add(Convolution2D(64, 3, 3, border_mode='same', subsample=(1, 1)))\n",
    "        model.add(Activation(activation_relu))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "        model.add(SpatialDropout2D(0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # Next, five fully connected layers\n",
    "        model.add(Dense(1164))\n",
    "        model.add(Activation(activation_relu))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(100))\n",
    "        model.add(Activation(activation_relu))\n",
    "\n",
    "        model.add(Dense(50))\n",
    "        model.add(Activation(activation_relu))\n",
    "\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation(activation_relu))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "        model.compile(optimizer=Adam(learning_rate), loss=\"mse\", )\n",
    "        return model\n",
    "        \n",
    "    def execute(self,train,valid, nspe=number_of_samples_per_epoch,nvspe=number_of_validation_samples):\n",
    "        self.history = self.model.fit_generator(train,\n",
    "                              samples_per_epoch=number_of_samples_per_epoch,\n",
    "                              nb_epoch=number_of_epochs,\n",
    "                              validation_data=valid,\n",
    "                              nb_val_samples=number_of_validation_samples,\n",
    "                              verbose=1)\n",
    "        \n",
    "    \n",
    "    def save(self, mname='model.json', wname='model.h5'):\n",
    "        jsmodel = self.model.to_json()\n",
    "        with open(mname, 'w') as jsfile:\n",
    "            json.dump(jsmodel, jsfile)\n",
    "\n",
    "        #self.model.save_weights(wname)\n",
    "        self.model.save(wname)\n",
    "        print(\"Model Saved in Json and h5 formats\")\n",
    "        \n",
    "    def history(self):\n",
    "        ### print the keys contained in the history object\n",
    "        print(self.history.history.keys())\n",
    "\n",
    "        ### plot the training and validation loss for each epoch\n",
    "        plt.plot(self.history.history['loss'])\n",
    "        plt.plot(self.history.history['val_loss'])\n",
    "        plt.title('model mean squared error loss')\n",
    "        plt.ylabel('mean squared error loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "        plt.show()     \n",
    "\n",
    "# create two generators for training and validation\n",
    "dp = DataProvider.DataProvider()\n",
    "train = dp.getbatch(64,'train')\n",
    "valid = dp.getbatch(64,'valid')\n",
    "bcm = BehavioralCloningModel()\n",
    "bcm.execute(train,valid,dp.train_length, dp.validation_length)\n",
    "bcm.save()\n",
    "bcm.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
